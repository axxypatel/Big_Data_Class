{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "kW6o-Aw2_zXc"
   },
   "source": [
    "#                               Allstate Claim Severity Prediction "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Allstate, a personal insurer in the United States, is continually seeking fresh ideas to improve their claims service for the over 16 million households they protect. Allstate is currently developing automated methods of predicting the cost, and hence severity, of claims. In this recruitment challenge, Kagglers are invited to show off their creativity and flex their technical chops by creating an algorithm which accurately predicts claims severity. Aspiring competitors will demonstrate insight into better ways to predict claims severity for the chance to be part of Allstate’s efforts to ensure a worry-free customer experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we have analysed the data from allstate claim severity dataset and tried to predict the loss based on the various features available in dataset. For this dataset, our main challenge is to process the 131 columns which also contain categorical columns having total category more than 100. One-hot-encoding is used to convert categorical feature into individual columns. As part of data pre-processing, various type of log transformation is used to reduce the skew of continuous variable. The prediction of target variable has been done using H2O framework as well as using python library like sklearn. In H2O, AutoML is used to predict the loss variable which generate the score of 1143.39 which is in top 46% among all teams. Using python sklearn library, XGBoost algorithm is used with fine tuning of hyperparameter give the score of 1107.50319 in public leader board and 1120.25985 in private leader board. This score lands in top 17% among all team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "H2O is high performance framework for machine learning algorithm which support most of the machine algorithm. AutoML is one of the machine learning algorithms available in H2O framework which train various models on provided dataset and give the list of models based on their performance in leader board. In this Notebook, We have used AutoML algorithm to train on allstate claim severity dataset and predict the \"loss\" target variable. We have also performed some basic data pre-processing steps like log and square root transformation for continuous feature to reduce the skew. Implementation of H2O for this kaggle compition not used by any kaggler. We have trained the AutoML algorithm on dataset and get top 10 models based on their performance by excluding xgboost algorithm. We have predicted the target variable for test dataset using the 3rd best model which is GBM and achieve result with MAE score of 1143.39. Due to more size of dataset, we choose google co-lab as our environment to run this notebook which also involved some extra coding for importing and exporting the dataset to google drive. The result of the target variable(“loss”) prediction is stored as csv file in google drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have also implemented xgboost algorithm from python sklearn library to achieve better result. XGBoost algorithm is one of the hot favourite algorithms among kaggles. Almost all kaggle compitition winner are using xgboost algorithm directly or in the form of stacked ensemble model. We have also used xgboost algorithm with fine tuning of hyperparameter which is different than what is available in public kernels. We have also tried to achieve less MAE score using log1p transformation of continuous features which is different than other public kernels. Our code also removes few categorical values from categorical features which are not common between train and test dataset to reduce the variance. one-hot-encoding of categorical features also helped the model to capture more detail from the data to predict better. Combination of this approaches help us to achieve MAE score of 1120.25985 in private leader board and 1107.50319 in public leader board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## H2O Framework:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RJ1qewSGyU6m"
   },
   "source": [
    "To install H2O, JRE must be install first to support H2O framework. H2O is installed using pip command after that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 467
    },
    "colab_type": "code",
    "id": "WNUb1xwqAOqz",
    "outputId": "592ba10b-c906-4ff9-c408-d4a1fcfd3ba9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "default-jre is already the newest version (2:1.10-63ubuntu1~02).\n",
      "default-jre set to manually installed.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 10 not upgraded.\n",
      "openjdk version \"10.0.2\" 2018-07-17\n",
      "OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4)\n",
      "OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)\n",
      "Collecting h2o\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/db/0d/e883b46c2ca0fefd24c15ff49180fe35aeaad12d8e42b0ed6e1be1664db8/h2o-3.22.1.4.tar.gz (120.9MB)\n",
      "\u001b[K    100% |████████████████████████████████| 120.9MB 274kB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from h2o) (2.18.4)\n",
      "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from h2o) (0.8.3)\n",
      "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from h2o) (0.16.0)\n",
      "Collecting colorama>=0.3.8 (from h2o)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a6/728666f39bfff1719fc94c481890b2106837da9318031f71a8424b662e12/colorama-0.4.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2018.11.29)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (2.6)\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (1.22)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->h2o) (3.0.4)\n",
      "Building wheels for collected packages: h2o\n",
      "  Building wheel for h2o (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/76/73/b8/8639930fbc56e9f26fac210f5e65dbe05a0c39396ddaf4a685\n",
      "Successfully built h2o\n",
      "Installing collected packages: colorama, h2o\n",
      "Successfully installed colorama-0.4.1 h2o-3.22.1.4\n"
     ]
    }
   ],
   "source": [
    "# required installation for h2o\n",
    "! apt-get install default-jre\n",
    "!java -version\n",
    "! pip install h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AMmrLH8CysXl"
   },
   "source": [
    "Necessary packages is imported which is being used in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7GDpCeDn_zXe"
   },
   "outputs": [],
   "source": [
    "# required packages\n",
    "import h2o\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from h2o.automl import H2OAutoML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R4Dx_sObzYBR"
   },
   "source": [
    "To start H2O framework, init function must be used to complete the setup of h2o. In h2o.init, parameters like maximum memory size, strick version check and port no is given. Here we have assign 6GB of memmory to h2o cluster since we have run it in google co-lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 508
    },
    "colab_type": "code",
    "id": "rzt9raTk_zXq",
    "outputId": "af5a963d-9623-4584-9ec0-b5fa503dc848"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:31556..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "  Java Version: openjdk version \"10.0.2\" 2018-07-17; OpenJDK Runtime Environment (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4); OpenJDK 64-Bit Server VM (build 10.0.2+13-Ubuntu-1ubuntu0.18.04.4, mixed mode)\n",
      "  Starting server from /usr/local/lib/python3.6/dist-packages/h2o/backend/bin/h2o.jar\n",
      "  Ice root: /tmp/tmpuyqdt2a4\n",
      "  JVM stdout: /tmp/tmpuyqdt2a4/h2o_unknownUser_started_from_python.out\n",
      "  JVM stderr: /tmp/tmpuyqdt2a4/h2o_unknownUser_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:31556\n",
      "Connecting to H2O server at http://127.0.0.1:31556... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>02 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>Etc/UTC</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.22.1.4</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>13 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>H2O_from_python_unknownUser_lirmyc</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>6 Gb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://127.0.0.1:31556</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.6.7 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ---------------------------------------------------\n",
       "H2O cluster uptime:         02 secs\n",
       "H2O cluster timezone:       Etc/UTC\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.22.1.4\n",
       "H2O cluster version age:    13 days\n",
       "H2O cluster name:           H2O_from_python_unknownUser_lirmyc\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    6 Gb\n",
       "H2O cluster total cores:    2\n",
       "H2O cluster allowed cores:  2\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://127.0.0.1:31556\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         Amazon S3, XGBoost, Algos, AutoML, Core V3, Core V4\n",
       "Python version:             3.6.7 final\n",
       "--------------------------  ---------------------------------------------------"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 65535 Highest port no\n",
    "port_no=random.randint(5555,55555)\n",
    "\n",
    "# setup h2o cluster\n",
    "h2o.init(strict_version_check=False,max_mem_size='6g',port=port_no) # start h2o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-Ma1kcYRze8Z"
   },
   "source": [
    "To import the train and test csv from google drive, below pydrive api is used to import the data from goole drive and dump into h20dataframe. User has to authenticate the access of the google drive when code is trying to access the file from google drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "W0VnGF-ILKrj",
    "outputId": "ed45eb9e-192b-4b27-adca-4e490662d1ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    100% |████████████████████████████████| 993kB 19.8MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "# install pydrive to connect the google drive\n",
    "!pip install -U -q PyDrive\n",
    " \n",
    "# google authentication to access the drive  \n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    " \n",
    "# 1. Authenticate and create the PyDrive client.\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ogWdC3xpzxQX"
   },
   "source": [
    "File from google drive will be accessed from it file id. We have to provide file id fro each file which is train.csv and test.csv. Below is the code to do the same operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 483
    },
    "colab_type": "code",
    "id": "PFahUPC-Lhcq",
    "outputId": "85976af7-d652-4bcd-95ad-36866bd47f0b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:googleapiclient.discovery_cache:file_cache is unavailable when using oauth2client >= 4.0.0\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 36, in autodetect\n",
      "    from google.appengine.api import memcache\n",
      "ModuleNotFoundError: No module named 'google.appengine'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 33, in <module>\n",
      "    from oauth2client.contrib.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.contrib.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 37, in <module>\n",
      "    from oauth2client.locked_file import LockedFile\n",
      "ModuleNotFoundError: No module named 'oauth2client.locked_file'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/__init__.py\", line 41, in autodetect\n",
      "    from . import file_cache\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/googleapiclient/discovery_cache/file_cache.py\", line 41, in <module>\n",
      "    'file_cache is unavailable when using oauth2client >= 4.0.0')\n",
      "ImportError: file_cache is unavailable when using oauth2client >= 4.0.0\n"
     ]
    }
   ],
   "source": [
    "# get the file using file id\n",
    "train_downloaded = drive.CreateFile({'id': '1cNP3WwM-737kOfTrTMJPQ9b0VOMwAzbQ'})\n",
    "train_downloaded.GetContentFile('train.csv')\n",
    "test_downloaded = drive.CreateFile({'id': '1sEkIqJYPnrtAhuiZJDEbprOupkiPgpjl'})\n",
    "test_downloaded.GetContentFile('test.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaRWSIk50GjQ"
   },
   "source": [
    "Importing the train.csv file and dumping into h2o dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "mSfp81RANwLy",
    "outputId": "7f98ec07-9e5c-4804-9f35-d8ecdb87bd30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# import csv file and dump into h2o dataframe\n",
    "train_data = h2o.import_file('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "B9M5w-QDQQob",
    "outputId": "bd160dc5-0a7e-4fb3-d8cb-1d70d48b4fe2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |█████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "test_data = h2o.import_file('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fKkZIBLE0VGc"
   },
   "source": [
    "Dataset contain few continueous variable and multiple categorical variable. It is required to do data preprocessing in order to get the best accuracy from the model. Initially, we have tried taking log/sqrt of continuoes variable since those featurs were highly skewed.  We have further imporved this features in our python version of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pi2KKCTd_zX-"
   },
   "outputs": [],
   "source": [
    "# take log transformation of continuoes feature\n",
    "test_data['cont1'] = test_data['cont1'].log()\n",
    "test_data['cont2'] = test_data['cont2'].log()\n",
    "test_data['cont4'] = test_data['cont4'].log()\n",
    "test_data['cont5'] = test_data['cont5'].log()\n",
    "test_data['cont8'] = test_data['cont8'].log()\n",
    "\n",
    "# take square root of continuoes feature\n",
    "test_data['cont10'] = test_data['cont10'].sqrt()\n",
    "test_data['cont13'] = test_data['cont13'].log()\n",
    "test_ids = test_data['id']\n",
    "test_data = test_data.drop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znwt1FZF_zYC"
   },
   "outputs": [],
   "source": [
    "# take log transformation of continuoes feature\n",
    "train_data['cont1'] = train_data['cont1'].log()\n",
    "train_data['cont2'] = train_data['cont2'].log()\n",
    "train_data['cont4'] = train_data['cont4'].log()\n",
    "train_data['cont5'] = train_data['cont5'].log()\n",
    "train_data['cont8'] = train_data['cont8'].log()\n",
    "\n",
    "# take square root of continuoes feature\n",
    "train_data['cont10'] = train_data['cont10'].sqrt()\n",
    "train_data['cont13'] = train_data['cont13'].log()\n",
    "train_data['loss'] = train_data['loss'].log()\n",
    "train_data = train_data.drop('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2183
    },
    "colab_type": "code",
    "id": "fTio-du8_zYJ",
    "outputId": "5a41a3f5-fac9-4097-c127-c757f9c5d9b5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat1',\n",
       " 'cat2',\n",
       " 'cat3',\n",
       " 'cat4',\n",
       " 'cat5',\n",
       " 'cat6',\n",
       " 'cat7',\n",
       " 'cat8',\n",
       " 'cat9',\n",
       " 'cat10',\n",
       " 'cat11',\n",
       " 'cat12',\n",
       " 'cat13',\n",
       " 'cat14',\n",
       " 'cat15',\n",
       " 'cat16',\n",
       " 'cat17',\n",
       " 'cat18',\n",
       " 'cat19',\n",
       " 'cat20',\n",
       " 'cat21',\n",
       " 'cat22',\n",
       " 'cat23',\n",
       " 'cat24',\n",
       " 'cat25',\n",
       " 'cat26',\n",
       " 'cat27',\n",
       " 'cat28',\n",
       " 'cat29',\n",
       " 'cat30',\n",
       " 'cat31',\n",
       " 'cat32',\n",
       " 'cat33',\n",
       " 'cat34',\n",
       " 'cat35',\n",
       " 'cat36',\n",
       " 'cat37',\n",
       " 'cat38',\n",
       " 'cat39',\n",
       " 'cat40',\n",
       " 'cat41',\n",
       " 'cat42',\n",
       " 'cat43',\n",
       " 'cat44',\n",
       " 'cat45',\n",
       " 'cat46',\n",
       " 'cat47',\n",
       " 'cat48',\n",
       " 'cat49',\n",
       " 'cat50',\n",
       " 'cat51',\n",
       " 'cat52',\n",
       " 'cat53',\n",
       " 'cat54',\n",
       " 'cat55',\n",
       " 'cat56',\n",
       " 'cat57',\n",
       " 'cat58',\n",
       " 'cat59',\n",
       " 'cat60',\n",
       " 'cat61',\n",
       " 'cat62',\n",
       " 'cat63',\n",
       " 'cat64',\n",
       " 'cat65',\n",
       " 'cat66',\n",
       " 'cat67',\n",
       " 'cat68',\n",
       " 'cat69',\n",
       " 'cat70',\n",
       " 'cat71',\n",
       " 'cat72',\n",
       " 'cat73',\n",
       " 'cat74',\n",
       " 'cat75',\n",
       " 'cat76',\n",
       " 'cat77',\n",
       " 'cat78',\n",
       " 'cat79',\n",
       " 'cat80',\n",
       " 'cat81',\n",
       " 'cat82',\n",
       " 'cat83',\n",
       " 'cat84',\n",
       " 'cat85',\n",
       " 'cat86',\n",
       " 'cat87',\n",
       " 'cat88',\n",
       " 'cat89',\n",
       " 'cat90',\n",
       " 'cat91',\n",
       " 'cat92',\n",
       " 'cat93',\n",
       " 'cat94',\n",
       " 'cat95',\n",
       " 'cat96',\n",
       " 'cat97',\n",
       " 'cat98',\n",
       " 'cat99',\n",
       " 'cat100',\n",
       " 'cat101',\n",
       " 'cat102',\n",
       " 'cat103',\n",
       " 'cat104',\n",
       " 'cat105',\n",
       " 'cat106',\n",
       " 'cat107',\n",
       " 'cat108',\n",
       " 'cat109',\n",
       " 'cat110',\n",
       " 'cat111',\n",
       " 'cat112',\n",
       " 'cat113',\n",
       " 'cat114',\n",
       " 'cat115',\n",
       " 'cat116',\n",
       " 'cont1',\n",
       " 'cont2',\n",
       " 'cont3',\n",
       " 'cont4',\n",
       " 'cont5',\n",
       " 'cont6',\n",
       " 'cont7',\n",
       " 'cont8',\n",
       " 'cont9',\n",
       " 'cont10',\n",
       " 'cont11',\n",
       " 'cont12',\n",
       " 'cont13',\n",
       " 'cont14']"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bgXh-dqp1QkN"
   },
   "source": [
    "Take target varible into y and rest will be added into x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IeQ1NB2__zYT"
   },
   "outputs": [],
   "source": [
    "# target variable\n",
    "y = 'loss'\n",
    "\n",
    "# create list for features\n",
    "x = [col for col in train_data.columns if col != y ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LRwtth9s1YCp"
   },
   "source": [
    "AutoML is automatic machine learning algorithm which run set of models on dataset provided into parameter and train each model on the same to get better accuracy. AutoML also do stacking of ensemble  models  which algorithm has already train the data on it. Techniques like one-hot-encoding and hyperparameter tunning will be automatically taken care by AutoML algorithm. We have removed the XGBoost algorithm as per the discussion with professor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "QAOv9Wuq_zYZ",
    "outputId": "a07bfec0-2609-4333-c0fc-fdb8a39ed778"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoML progress: |████████████████████████████████████████████████████████| 100%\n"
     ]
    }
   ],
   "source": [
    "# AutoML without xgboost\n",
    "auto_model = H2OAutoML(max_models=10,seed=1234,max_runtime_secs=3600*6,exclude_algos=[\"XGBoost\"])\n",
    "\n",
    "# train AutoML\n",
    "auto_model.train(x=x,y=y,training_frame=train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aL0CIXEa2qL0"
   },
   "source": [
    "Leaderboard shows all models which trained on the given dataset in the ascending order based on the loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "hWxGwQEm_zYh",
    "outputId": "90bad5db-fbf5-4109-8aa0-31b1b56debfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>model_id                                           </th><th style=\"text-align: right;\">  mean_residual_deviance</th><th style=\"text-align: right;\">    rmse</th><th style=\"text-align: right;\">     mse</th><th style=\"text-align: right;\">     mae</th><th style=\"text-align: right;\">    rmsle</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>StackedEnsemble_AllModels_AutoML_20190301_122806   </td><td style=\"text-align: right;\">                0.291101</td><td style=\"text-align: right;\">0.539538</td><td style=\"text-align: right;\">0.291101</td><td style=\"text-align: right;\">0.4168  </td><td style=\"text-align: right;\">0.0639199</td></tr>\n",
       "<tr><td>StackedEnsemble_BestOfFamily_AutoML_20190301_122806</td><td style=\"text-align: right;\">                0.292526</td><td style=\"text-align: right;\">0.540857</td><td style=\"text-align: right;\">0.292526</td><td style=\"text-align: right;\">0.417928</td><td style=\"text-align: right;\">0.0640752</td></tr>\n",
       "<tr><td>GBM_grid_1_AutoML_20190301_122806_model_1          </td><td style=\"text-align: right;\">                0.295324</td><td style=\"text-align: right;\">0.543437</td><td style=\"text-align: right;\">0.295324</td><td style=\"text-align: right;\">0.420865</td><td style=\"text-align: right;\">0.0643711</td></tr>\n",
       "<tr><td>GBM_2_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.297917</td><td style=\"text-align: right;\">0.545817</td><td style=\"text-align: right;\">0.297917</td><td style=\"text-align: right;\">0.422885</td><td style=\"text-align: right;\">0.0646055</td></tr>\n",
       "<tr><td>GBM_1_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.298133</td><td style=\"text-align: right;\">0.546015</td><td style=\"text-align: right;\">0.298133</td><td style=\"text-align: right;\">0.42296 </td><td style=\"text-align: right;\">0.0646462</td></tr>\n",
       "<tr><td>GBM_3_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.298973</td><td style=\"text-align: right;\">0.546784</td><td style=\"text-align: right;\">0.298973</td><td style=\"text-align: right;\">0.42348 </td><td style=\"text-align: right;\">0.0647011</td></tr>\n",
       "<tr><td>DeepLearning_1_AutoML_20190301_122806              </td><td style=\"text-align: right;\">                0.300896</td><td style=\"text-align: right;\">0.54854 </td><td style=\"text-align: right;\">0.300896</td><td style=\"text-align: right;\">0.424569</td><td style=\"text-align: right;\">0.065013 </td></tr>\n",
       "<tr><td>GBM_4_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.302036</td><td style=\"text-align: right;\">0.549578</td><td style=\"text-align: right;\">0.302036</td><td style=\"text-align: right;\">0.425846</td><td style=\"text-align: right;\">0.065001 </td></tr>\n",
       "<tr><td>GBM_5_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.30243 </td><td style=\"text-align: right;\">0.549936</td><td style=\"text-align: right;\">0.30243 </td><td style=\"text-align: right;\">0.425669</td><td style=\"text-align: right;\">0.0650628</td></tr>\n",
       "<tr><td>GLM_grid_1_AutoML_20190301_122806_model_1          </td><td style=\"text-align: right;\">                0.318097</td><td style=\"text-align: right;\">0.564001</td><td style=\"text-align: right;\">0.318097</td><td style=\"text-align: right;\">0.440537</td><td style=\"text-align: right;\">0.0665769</td></tr>\n",
       "<tr><td>DRF_1_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.320756</td><td style=\"text-align: right;\">0.566353</td><td style=\"text-align: right;\">0.320756</td><td style=\"text-align: right;\">0.440633</td><td style=\"text-align: right;\">0.0668141</td></tr>\n",
       "<tr><td>XRT_1_AutoML_20190301_122806                       </td><td style=\"text-align: right;\">                0.329022</td><td style=\"text-align: right;\">0.573604</td><td style=\"text-align: right;\">0.329022</td><td style=\"text-align: right;\">0.44803 </td><td style=\"text-align: right;\">0.0676798</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# automl leaderboard\n",
    "lb = auto_model.leaderboard\n",
    "lb.head(rows=lb.nrows) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 617
    },
    "colab_type": "code",
    "id": "XazlPm8K_zYq",
    "outputId": "c2226213-7ffa-4029-a4a6-00b4a5e4a084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Details\n",
      "=============\n",
      "H2OStackedEnsembleEstimator :  Stacked Ensemble\n",
      "Model Key:  StackedEnsemble_AllModels_AutoML_20190301_122806\n",
      "No model summary for this model\n",
      "\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.23555145143535214\n",
      "RMSE: 0.48533643118495867\n",
      "MAE: 0.37388336828602403\n",
      "RMSLE: 0.05779152346812914\n",
      "R^2: 0.6426307812986011\n",
      "Mean Residual Deviance: 0.23555145143535214\n",
      "Null degrees of freedom: 188317\n",
      "Residual degrees of freedom: 188310\n",
      "Null deviance: 124125.34686802176\n",
      "Residual deviance: 44358.578231402644\n",
      "AIC: 262166.2893043658\n",
      "\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on cross-validation data. **\n",
      "\n",
      "MSE: 0.2911007174417809\n",
      "RMSE: 0.5395375032764459\n",
      "MAE: 0.41679958205424467\n",
      "RMSLE: 0.06391987178355957\n",
      "R^2: 0.5583536619200354\n",
      "Mean Residual Deviance: 0.2911007174417809\n",
      "Null degrees of freedom: 188317\n",
      "Residual degrees of freedom: 188310\n",
      "Null deviance: 124126.22133413701\n",
      "Residual deviance: 54819.5049072013\n",
      "AIC: 302040.73289040214\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To get the leader of AutoML algorithm\n",
    "auto_model.leader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CDbPJuqk3fTr"
   },
   "source": [
    "We have tried to predict the target variable using the best model of AutoML but model give error due to categorical variables. We have tried to reach the engineers of H2O and found that it is existing defect in the H2O 3.22 version which will be fixed in upcoming relase. Please refer below link for more information.\n",
    "\n",
    "https://0xdata.atlassian.net/browse/PUBDEV-6266"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 932
    },
    "colab_type": "code",
    "id": "x8KeHLQ5_zY0",
    "outputId": "ca694e65-1b13-44d1-e769-f7ae4f3afe34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stackedensemble prediction progress: |█████ (failed)\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-4a58bf7a746e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mauto_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/model/model_base.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, test_data, custom_metric, custom_metric_func)\u001b[0m\n\u001b[1;32m    191\u001b[0m         j = H2OJob(h2o.api(\"POST /4/Predictions/models/%s/frames/%s\" % (self.model_id, test_data.frame_id), data = {'custom_metric_func': custom_metric_func}),\n\u001b[1;32m    192\u001b[0m                    self._model_json[\"algo\"] + \" prediction\")\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mh2o\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdest_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/h2o/job.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, verbose_model_scoring_history)\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"stacktrace\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 raise EnvironmentError(\"Job with key {} failed with an exception: {}\\nstacktrace: \"\n\u001b[0;32m---> 77\u001b[0;31m                                        \"\\n{}\".format(self.job_key, self.exception, self.job[\"stacktrace\"]))\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job with key %s failed with an exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: Job with key $03017f000001457bffffffff$_9673b921330e1954c96949be90004106 failed with an exception: DistributedException from /127.0.0.1:31556: 'Categorical value out of bounds, got 133, next cat starts at 457', caused by java.lang.AssertionError: Categorical value out of bounds, got 133, next cat starts at 457\nstacktrace: \nDistributedException from /127.0.0.1:31556: 'Categorical value out of bounds, got 133, next cat starts at 457', caused by java.lang.AssertionError: Categorical value out of bounds, got 133, next cat starts at 457\n\tat water.MRTask.getResult(MRTask.java:478)\n\tat water.MRTask.getResult(MRTask.java:486)\n\tat water.MRTask.doAll(MRTask.java:390)\n\tat water.MRTask.doAll(MRTask.java:396)\n\tat hex.StackedEnsembleModel.predictScoreImpl(StackedEnsembleModel.java:161)\n\tat hex.Model.score(Model.java:1360)\n\tat water.api.ModelMetricsHandler$1.compute2(ModelMetricsHandler.java:374)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1395)\n\tat jsr166y.CountedCompleter.exec(CountedCompleter.java:468)\n\tat jsr166y.ForkJoinTask.doExec(ForkJoinTask.java:263)\n\tat jsr166y.ForkJoinPool$WorkQueue.runTask(ForkJoinPool.java:974)\n\tat jsr166y.ForkJoinPool.runWorker(ForkJoinPool.java:1477)\n\tat jsr166y.ForkJoinWorkerThread.run(ForkJoinWorkerThread.java:104)\nCaused by: java.lang.AssertionError: Categorical value out of bounds, got 133, next cat starts at 457\n\tat hex.DataInfo.getCategoricalId(DataInfo.java:981)\n\tat hex.DataInfo.getCategoricalId(DataInfo.java:960)\n\tat hex.glm.GLMModel.score0(GLMModel.java:1184)\n\tat hex.Model.score0(Model.java:1684)\n\tat hex.Model$BigScore.score0(Model.java:1628)\n\tat hex.Model$BigScore.map(Model.java:1606)\n\tat water.MRTask.compute2(MRTask.java:657)\n\tat water.MRTask.compute2(MRTask.java:591)\n\tat water.MRTask.compute2(MRTask.java:591)\n\tat water.MRTask.compute2(MRTask.java:591)\n\tat water.H2O$H2OCountedCompleter.compute1(H2O.java:1398)\n\tat hex.Model$BigScore$Icer.compute1(Model$BigScore$Icer.java)\n\tat water.H2O$H2OCountedCompleter.compute(H2O.java:1394)\n\t... 5 more\n"
     ]
    }
   ],
   "source": [
    "# predict target variable using leader model\n",
    "y_pred = auto_model.leader.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4LAli7IM4YW6"
   },
   "source": [
    "Since stacked ensemble model doesn't work for this dataset. we have used the 3rd best model from the leader board to predict target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zol2K7a6HeOo"
   },
   "outputs": [],
   "source": [
    "# Get Third best model from the leader board\n",
    "model6 = h2o.get_model(auto_model.leaderboard.as_data_frame()['model_id'][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "colab_type": "code",
    "id": "uYw-C0f3H37D",
    "outputId": "ea950a7b-b75c-4344-ceda-004f96b45d3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbm prediction progress: |████████████████████████████████████████████████| 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat89' has levels not trained on: [F]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat92' has levels not trained on: [E, G]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat96' has levels not trained on: [H]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat99' has levels not trained on: [U]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat103' has levels not trained on: [M]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat106' has levels not trained on: [Q]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat109' has levels not trained on: [AD]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat110' has levels not trained on: [BH, CA, EN]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat111' has levels not trained on: [L]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat113' has levels not trained on: [AA, R]\n",
      "  warnings.warn(w)\n",
      "/usr/local/lib/python3.6/dist-packages/h2o/job.py:69: UserWarning: Test/Validation dataset column 'cat116' has levels not trained on: [A, AI, AQ, BE, BH, BJ, BN, BR, DB, EM, ER, ET, EX, FY, HS, IS, IW, JS, KO, LP, LS, MX, N]\n",
      "  warnings.warn(w)\n"
     ]
    }
   ],
   "source": [
    "# predict the target variable\n",
    "loss_pred = model6.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "ZQk4yW83IKFo",
    "outputId": "bbaebaf5-db7a-440c-d7cf-0f653d8fcb52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  predict</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">  7.37521</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.55873</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  9.15336</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.67703</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.72708</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.65227</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.52222</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  6.81097</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  7.73643</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  8.05834</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cpO5wNJk5BqF"
   },
   "source": [
    "During the data preprocessing, we have taken log of target variable to train the model so we have to rescale it by taking exponential of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WecxAEPr_zY7"
   },
   "outputs": [],
   "source": [
    "# take exponential of target variable\n",
    "loss_pred_act = loss_pred.exp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "bjGxkbHIIVI3",
    "outputId": "003db674-ce83-4b7a-d955-e4311e315576"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(125546, 1)"
      ]
     },
     "execution_count": 48,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_pred_act.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y48JTwwZI0b8"
   },
   "outputs": [],
   "source": [
    "# combine id and target variable\n",
    "submit_data = test_ids.cbind(loss_pred_act)\n",
    "submit_data.columns = ['id','loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "3KRO-zpWJg8Z",
    "outputId": "e0072cf8-d682-4d3b-c6a4-ae1e7cc9abe5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th style=\"text-align: right;\">  id</th><th style=\"text-align: right;\">    loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td style=\"text-align: right;\">   4</td><td style=\"text-align: right;\">1523.27 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   6</td><td style=\"text-align: right;\">1964.07 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">   9</td><td style=\"text-align: right;\">9552.08 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  12</td><td style=\"text-align: right;\">5763.96 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  15</td><td style=\"text-align: right;\"> 741.753</td></tr>\n",
       "<tr><td style=\"text-align: right;\">  17</td><td style=\"text-align: right;\">2075.69 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  21</td><td style=\"text-align: right;\">1634.98 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  28</td><td style=\"text-align: right;\">1047.09 </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  32</td><td style=\"text-align: right;\">2479    </td></tr>\n",
       "<tr><td style=\"text-align: right;\">  43</td><td style=\"text-align: right;\">2679.47 </td></tr>\n",
       "</tbody>\n",
       "</table>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "id": "ygluTwDIJzBt",
    "outputId": "608d0806-df17-4b8b-a212-e9b7578eeda4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at drive; to attempt to forcibly remount, call drive.mount(\"drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "# mount the google drive \n",
    "from google.colab import drive\n",
    "drive.mount('drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wnXnnn9WKZVs"
   },
   "outputs": [],
   "source": [
    "# conver h2o dataframe to pandas dataframe\n",
    "df_submit = submit_data.as_data_frame(use_pandas=True,header=True)\n",
    "\n",
    "# write dataframe to csv\n",
    "df_submit.to_csv('submit2.csv')\n",
    "\n",
    "# save the csv into google drive\n",
    "!cp submit2.csv drive/My\\ Drive/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion from H2O Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rW9BIKoeyoJx"
   },
   "source": [
    "The submission file is created using third best model from AutoML algorithm which gave MAE of 1143.39819 which comes under top 46% amoung all teams. The score could be better using stacked ensemble models which is the leader model from the AutoML algorithm but due to existing bug present in the H2O version 3.22, It is not possible to run the stacked ensemble model from AutoML with this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After trying two approach, Below are the results for each approach.\n",
    "\n",
    "* H2O Framework: \n",
    "Using H2O, We have used AutoML algorithm to train on dataset to get the best model. We have taken 3rd best model which GBM to predict the target variable(\"loss\"). After prediction, we got MAE as 1143.39 which comes under top 46% amoung all teams. Stacked ensebmle model could have done better job than GBM model but due to existing issue in the H2O 3.22 version, we were not able to used stacked ensebmle model to predict the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Python Sklearn Library: Using sklearn library, We have train our model on dataset with fine tuning of hyperparameter to get the best MAE score which is 1120.25985 on private leader board and 1107.50319 on public leader board. This score comes under top 17% among all the teams of this competition. During this, approaches like data pre-processing, fine tuning of hyperparameter of xgboost, one-hot-encoding, collinearity check and removal of uncommon categories between train and test dataset help us to achieve better results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contributions statement:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author has completed this kaggle challenge using two approach which included H2O framework by implementing the AutoML algorithm and using python sklearn library after fine tuning of xgboost algorithm to get better result. Authors has also done experiment on data pre-processing by using log, sqrt or log1p transformation to train and test data to reduce the skew of individual continuous variable. Below approaches has been implemented by the individual team member.\n",
    "\n",
    "Akshay:\n",
    "\n",
    "* Used H2O framework to get extract the train and test file from google drive and do initial data pre-processing where we have used log and square root transformation to reduce the skew of continuous features and convert into normal distributed data.\n",
    "\n",
    "* AutoML is used to train on dataset to get the best model. Author has used the GBM model to predict the target variable with MAE score of 1143.39. \n",
    "\n",
    "* Final submission file created for H2O code and upload to google drive to submit into kaggle competition.\n",
    "\n",
    "Akshay:\n",
    "*  Using python, Author has tried log(1+x) transformation for data pre-processing which give less skewed data and help model to increase the accuracy.\n",
    "\n",
    "* Comparison is shown using graph for continuous feature which include values before transformation and after transformation.\n",
    "\n",
    "* Density plot are also shown in the notebook to check the distribution of features.\n",
    "\n",
    "* Author has checked the correlation between continuous features and remove some based on their correlation value.\n",
    "\n",
    "* Remove the same category values from categorical features which are not common between train and test file.\n",
    "\n",
    "* One-hot-encoding technique is implemented to convert categorical features.\n",
    "\n",
    "* Fine tuning of XGBoost is performed to get better accuracy for this dataset.\n",
    "\n",
    "* Create submission file for python implemented code which give MAE score 1120.25985.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://xgboost.readthedocs.io/en/latest/python/python_api.html\n",
    "\n",
    "* https://www.kaggle.com/c/allstate-claims-severity\n",
    "\n",
    "* http://docs.h2o.ai/h2o/latest-stable/h2o-docs/automl.html\n",
    "\n",
    "* http://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-munging.html\n",
    "\n",
    "* https://www.kaggle.com/modkzs/lexical-encoding-feature-comb?scriptVersionId=441521\n",
    "\n",
    "* https://www.kaggle.com/iglovikov/xgb-1114\n",
    "\n",
    "* https://www.kaggle.com/aliajouz/singel-model-lb-1117\n",
    "\n",
    "* https://www.kaggle.com/c/allstate-claims-severity/discussion/25609"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licence:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2018 Akshay Patel\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment2_Allstate_kaggle_compitition.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
